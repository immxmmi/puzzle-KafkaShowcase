# Kafka Showcase

> üõ†Ô∏è **Tools Required**:  
> - [Minikube](https://minikube.sigs.k8s.io/docs/start/)  
> - [kubectl](https://kubernetes.io/docs/tasks/tools/)  
> - [make](https://www.gnu.org/software/make/)  
> - [Docker](https://docs.docker.com/get-docker/)  
> - [Helm](https://helm.sh/docs/intro/install/)  
> - [ArgoCD CLI](https://argo-cd.readthedocs.io/en/stable/cli_installation/) *(optional, but recommended)*

This project demonstrates how to set up a local Kafka cluster on **Minikube** using the **Strimzi Operator** and Helm, including a complete MQTT-to-Kafka data pipeline and an interactive showcase.

## üìå Requirements

To run this demo environment, you need:

- A **Minikube** cluster with:
  - Minimum **4‚Äì6 GB RAM** (more is better for scaling)
  - At least **3 CPUs**
- `kubectl`
- `make`
- Internet access

## üñ•Ô∏è Optional: Setup Minikube, Homebrew, Docker, Helm, and kubectl


### Install Homebrew (macOS/Linux)
  ```bash
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
 ```

### Install Minikube

- **macOS (with Homebrew)**:
  ```bash
  brew install minikube
  ```

- **Linux (Ubuntu)**:
  ```bash
  curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
  sudo install minikube-linux-amd64 /usr/local/bin/minikube
  ```


### Install Docker

- **macOS**: [Docker Desktop](https://docs.docker.com/desktop/install/mac-install/)
- **Ubuntu**:
  ```bash
  sudo apt update
  sudo apt install docker.io
  sudo usermod -aG docker $USER
  ```

### Install Helm (macOS/Linux)

```bash
brew install helm
```

### Install kubectl (macOS/Linux)

```bash
brew install kubectl
```

## üöÄ How It Works

This setup uses:
- **Strimzi Operator** to deploy and manage Kafka clusters
- A **Kafka UI** for browsing topics and messages (Argocd required)
- An **ArgoCD-based showcase** simulating solar panel data flowing through MQTT ‚Üí Kafka

## üõ†Ô∏è Step-by-Step Instructions

### 1. Install the Strimzi Operator

First, deploy the Strimzi Operator, which is required for managing Kafka clusters in Kubernetes:

```bash
make install_strimzi
```

This deploys the Operator in the `strimzi` namespace. It will watch the `kafka` namespace and manage all Kafka resources created there.

### 2. Choose and Deploy a Kafka Cluster

You can choose between several predefined Kafka cluster types:

- Basic, in-memory cluster:
  ```bash
  make create_simple_cluster
  ```

- Cluster with persistent storage:
  ```bash
  make create_simple_cluster_persistent
  ```

- *(Coming soon)* Cluster using NodePools and KRaft (no Zookeeper):
  ```bash
  make create_simple_cluster_with_nodepool
  ```
  ‚ö†Ô∏è Currently not available ‚Äî works only with KRaft mode, not Zookeeper.

All clusters come with **2 Kafka brokers**.

### 3. Kafka Cluster Ready ‚Äì Connect to It

Once deployed, your Kafka cluster is accessible inside your Kubernetes network via:

```
mykafka-cluster-kafka-bootstrap.kafka.svc.cluster.local:9092
```

> Topic auto-creation is **disabled**, so all topics must be declared explicitly.

### 4. (Optional) Install Kafka UI

You can visualize your cluster with:

```bash
make install_kafka_ui
```

This deploys a Kafka UI to interact with brokers, topics, and messages directly. Use this to inspect real-time data during the showcase.

## üì¶ Install ArgoCD

Run:

```bash
make install_argocd
```

This installs ArgoCD in your Minikube cluster and prepares it for managing Helm-based applications. This step is required before deploying applications that require ArgoCD, such as the Kafka UI and Solar-System showcase.

## üåû Solar-System Showcase

This showcase simulates data generated by **solar panels**.

- Each panel produces fake but realistic metrics (e.g. power output, temperature).
- Data is sent via **MQTT** to a **bridge**, which converts and forwards it to Kafka.
- Kafka topics are automatically created for storing this data.

### Requirements

This showcase requires **ArgoCD** to manage deployments using Helm charts.  
Additionally, the Kafka UI also requires **ArgoCD** for deployment.

### B. Install the ArgoCD CLI (Optional)

If you're using Homebrew:

```bash
make install_argocd_cli
```

### C. Log in to ArgoCD (Minikube only)

To log in using the default setup for Minikube:

```bash
make login_argocd
```

> ‚ö†Ô∏è This only works if you're running **Minikube**. For other Kubernetes clusters, you‚Äôll need to log in manually using the proper `argocd login` command.

### D. Add ArgoCD Project

This command adds the Helm chart repository that contains the showcase components:

```bash
make add_argocd_project
```

It connects ArgoCD with the required Helm charts used in the showcase.

### E. Deploy the Showcase

Now deploy the full solar showcase:

```bash
make add_showcase_solar
```

This will:
- Deploy the data generator (solar panel simulator)
- Deploy the MQTT broker and Kafka bridge
- Create the necessary Kafka topics
- Connect everything to your running Kafka cluster

You can verify functionality in the Kafka UI or by listing topics:

```bash
make topics
```

Or view partition info:

```bash
make partitions
```

## üîå Using the Cluster in Your Own Projects

To produce or consume data from the Kafka cluster inside Kubernetes, use the following bootstrap address:

```
mykafka-cluster-kafka-bootstrap.kafka.svc.cluster.local:9092
```

This works from inside the cluster or with port-forwarding from outside.

## ‚öñÔ∏è Advanced: Scaling & Rebalancing

If you want to scale your Kafka brokers up or down dynamically:

- To **add a broker**:
  ```bash
  make add_kafka_broker
  ```

- To **remove a broker**:
  ```bash
  make remove_kafka_broker
  ```

These commands update the StatefulSet that defines your Kafka brokers, allowing Strimzi to rebalance automatically. You can also trigger:

 - `make auto-rebalance` ‚Äì runs a rebalance automatically
 - `make upscale-rebalance` ‚Äì rebalances after scaling up

Rebalancing is necessary to evenly distribute Kafka partitions across brokers after scaling events.

 - To **automatically rebalance**:
   ```bash
   make auto-rebalnce
   ```

 - To **rebalance after scaling up**:
   ```bash
   make upscale-rebalance
   ```

 - (Optional) You can also manually approve rebalances or check their status using:
   - `make wait_for_rebalance_status REBALANCE_NAME=name`
   - `make approve_rebalance REBALANCE_NAME=name`

---

## üìä Kafka Topics & Partitions

If you don't want to use the Kafka UI, you can inspect the cluster manually:

 - **List all topics**:
   ```bash
   make topics
   ```

 - **Describe a topic** (requires setting the `TOPIC` variable):
   ```bash
   make describe TOPIC=your-topic-name
   ```

 - **View partition information**:
   ```bash
   make partitions
   ```
Enjoy your local event-driven architecture playground! üõ∞Ô∏è
# puzzle-KafkaShowcase
